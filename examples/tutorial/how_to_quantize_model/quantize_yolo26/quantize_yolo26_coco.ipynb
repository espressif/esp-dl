{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv26 Quantization Aware Training (QAT)\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete Quantization Aware Training (QAT) pipeline for **YOLOv26**, tailored for deployment on **ESP32-P4** (via ESP-DL and ESP-PPQ).\n",
    "\n",
    "### Key Features of YOLOv26\n",
    "YOLOv26 represents an evolution in the YOLO architecture focusing on efficiency and end-to-end deployment.\n",
    "- **NMS-Free Prediction**: Utilizes a dual-head architecture (One-to-Many for training signal, One-to-One for inference), eliminating the need for Non-Maximum Suppression (NMS) during inference.\n",
    "- **RegMax=1**: Unlike YOLOv8 (RegMax=16) which uses Distribution Focal Loss (DFL), YOLOv26 uses direct regression (`RegMax=1`), reducing output channel complexity and post-processing overhead.\n",
    "- **Efficient Attention**: Incorporates attention mechanisms (e.g., C2PSA) optimized for low-latency edge devices.\n",
    "\n",
    "### Optimizer Choice: SGD vs MuoSGD\n",
    "For this QAT pipeline, we have chosen **SGD (Stochastic Gradient Descent)** over **MuoSGD**.\n",
    "- **Reason**: We involve only a small fine-tuning step on a model that is already pretrained and calibrated.\n",
    "- **Simplicity**: Since the model starts in a good state, we do not need the additional complexity of MuoSGD (which is designed for more aggressive topology changes or from-scratch quantization training). Standard SGD is sufficient and effective for this task.\n",
    "\n",
    "### QAT Workflow Specifics\n",
    "This pipeline addresses specific challenges in quantizing YOLOv26 for embedded targets:\n",
    "1.  **Custom Export Patches**: \n",
    "    - Patches `Attention` modules to use static reshaping (`view(-1, ...)`), ensuring compatibility with ESP-DL's static graph compiler.\n",
    "    - Preserves all 6 output heads (3x Aux, 3x Main) during QAT to calculate accurate loss, while enabling `dynamic=False` export for final deployment.\n",
    "2.  **Sensitive Layer Analysis**: Automatically identifies and disables quantization for the Auxiliary Branch to stabilize training.\n",
    "3.  **PPQ Integration**: Uses the internal quantization pipeline (Simplify -> Fusion -> Parameter Quantize -> Calibration -> Finetuning) before starting the QAT loop.\n",
    "4.  **Custom Validator**: A dedicated validator that mimics the Quantized Graph execution to report real on-target mAP metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: esp-ppq==1.2.4 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: onnx==1.17.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: onnxruntime>=1.19.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 3)) (1.19.2)\n",
      "Requirement already satisfied: torch>=2.4.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 4)) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.19.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 5)) (0.23.0+cu126)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: ultralytics==8.4.7 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 7)) (8.4.7)\n",
      "Requirement already satisfied: onnxsim>=0.4.36 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 8)) (0.4.36)\n",
      "Requirement already satisfied: cryptography>=45.0.4 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (46.0.2)\n",
      "Requirement already satisfied: flatbuffers>=25.2.10 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (25.2.10)\n",
      "Requirement already satisfied: setuptools>=75.3.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (78.1.0)\n",
      "Requirement already satisfied: toml in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnx==1.17.0->-r requirements.txt (line 2)) (4.25.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (3.9.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (5.9.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (1.36.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (2.0.18)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxruntime>=1.19.0->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxruntime>=1.19.0->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxruntime>=1.19.0->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (2024.6.1)\n",
      "Requirement already satisfied: rich in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxsim>=0.4.36->-r requirements.txt (line 8)) (13.9.4)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from cryptography>=45.0.4->esp-ppq==1.2.4->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (6.5.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from polars>=0.20.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.36.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from sympy->onnxruntime>=1.19.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from tqdm>=4.67.1->esp-ppq==1.2.4->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from coloredlogs->onnxruntime>=1.19.0->-r requirements.txt (line 3)) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from jinja2->torch>=2.4.0->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from rich->onnxsim>=0.4.36->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from rich->onnxsim>=0.4.36->-r requirements.txt (line 8)) (2.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from cffi>=2.0.0->cryptography>=45.0.4->esp-ppq==1.2.4->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.19.0->-r requirements.txt (line 3)) (3.5.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->onnxsim>=0.4.36->-r requirements.txt (line 8)) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Imports\n",
    "import os\n",
    "import sys\n",
    "# Add pipeline source to path for local imports\n",
    "sys.path.append('scripts')\n",
    "\n",
    "import types\n",
    "import torch\n",
    "import esp_ppq.lib as PFL\n",
    "from esp_ppq.executor import TorchExecutor\n",
    "from esp_ppq.core import QuantizationVisibility, TargetPlatform\n",
    "from esp_ppq.api import get_target_platform\n",
    "from esp_ppq.api.interface import load_onnx_graph\n",
    "from esp_ppq.quantization.optim import (\n",
    "    QuantizeSimplifyPass, QuantizeFusionPass, ParameterQuantizePass,\n",
    "    RuntimeCalibrationPass, PassiveParameterQuantizePass, QuantAlignmentPass\n",
    ")\n",
    "from ultralytics.data.utils import check_det_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Important Configuration ---\n",
    "IMG_SZ_I = 512   # any size\n",
    "PLATFORM = \"s3\"  # p4 or s3\n",
    "DATA_YAML_FILE_I = \"coco.yaml\" # Ultralytics default YAML file ,you can use your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "class QATConfig:\n",
    "    # Training Parameters\n",
    "    EPOCHS = 10           # 640 img_sz need about 10 epochs\n",
    "    BATCH_SIZE = 14       # on 8GB VRAM use 14 for 640 img_sz and 20 for 512 img_sz\n",
    "    IMG_SZ = IMG_SZ_I\n",
    "    DATA_FRACTION = 1.0   # Use 0.005 (0.5%) of dataset for fast debugging\n",
    "    SEED = 1234\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Optimizer\n",
    "    OPTIMIZER_LR = 1e-6\n",
    "    OPTIMIZER_MOMENTUM = 0.937\n",
    "    OPTIMIZER_WEIGHT_DECAY = 5e-4\n",
    "    \n",
    "    # Data Settings\n",
    "    DATA_YAML_FILE = DATA_YAML_FILE_I\n",
    "    DATA_FALLBACK_PATH = \"coco2017/images/train2017\"\n",
    "    CALIB_MAX_IMAGES = 8192\n",
    "    CALIB_VALID_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "    \n",
    "    # Quantization Settings\n",
    "    TARGET_PLATFORM = get_target_platform(\"esp32\"+PLATFORM, 8)\n",
    "    CALIB_STEPS = 32\n",
    "    QUANT_CALIB_METHOD = \"kl\"\n",
    "    QUANT_ALIGNMENT = \"Align to Output\"\n",
    "    EXPORT_OPSET = 13\n",
    "    EXPORT_DYNAMIC = False \n",
    "    \n",
    "    # Loss Defaults (Standard YOLOv8/v10/v26 defaults)\n",
    "    LOSS_DEFAULTS = {\n",
    "        'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0,\n",
    "        'label_smoothing': 0.0, 'nbs': 64, 'hsv_h': 0.015, 'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5,\n",
    "        'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5,\n",
    "        'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0,\n",
    "    }\n",
    "\n",
    "    # Model Paths\n",
    "    # Assuming current directory\n",
    "    BASE_DIR = os.getcwd()\n",
    "    MODEL_NAME = \"yolo26n\"\n",
    "    PT_FILE = f\"{MODEL_NAME}.pt\"\n",
    "    ONNX_FILE = f\"{MODEL_NAME}_train.onnx\"\n",
    "    \n",
    "    # Derived Paths - Output Structure updated for GitHub workflow\n",
    "    ESPDL_OUTPUT_DIR = os.path.join(BASE_DIR, \"output\", f\"{DATA_YAML_FILE_I[:-5]}_{IMG_SZ}_s8_{PLATFORM}\")\n",
    "    ONNX_PATH = os.path.join(ESPDL_OUTPUT_DIR, ONNX_FILE)\n",
    "    \n",
    "    # Plotting\n",
    "    VAL_PLOT_MAX_BATCHES = 3\n",
    "\n",
    "    # Validation Batch Size\n",
    "    VAL_BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered 'Mod' handler for PPQ.\n",
      "Virtual Config injected and Modules initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- Virtual Module Injection ---\n",
    "# This tricks Python into thinking 'config.py' exists and contains our QATConfig class.\n",
    "# This allows 'trainer.py' and 'utils.py' to do 'from config import QATConfig'\n",
    "\n",
    "if 'config' in sys.modules:\n",
    "    # If it exists, update it\n",
    "    sys.modules['config'].QATConfig = QATConfig\n",
    "else:\n",
    "    # Create a dummy module\n",
    "    config_module = types.ModuleType('config')\n",
    "    config_module.QATConfig = QATConfig\n",
    "    sys.modules['config'] = config_module\n",
    "\n",
    "# Must ensure output directory exists for config files early usage if any\n",
    "if not os.path.exists(QATConfig.ESPDL_OUTPUT_DIR):\n",
    "    os.makedirs(QATConfig.ESPDL_OUTPUT_DIR)\n",
    "\n",
    "# Now we can safely import our local modules that depend on 'config'\n",
    "from utils import seed_everything, register_mod_op, patch_v8_detection_loss, get_exclusive_ancestors\n",
    "from dataset import get_calibration_loader, get_train_loader\n",
    "from trainer import QATTrainer\n",
    "from export import apply_export_patches, ESP_YOLO\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed_everything(QATConfig.SEED)\n",
    "register_mod_op()\n",
    "patch_v8_detection_loss()\n",
    "print(\"Virtual Config injected and Modules initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP-PPQ ONNX Compatibility Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ESP-PPQ Runtime Patches...\n",
      "  [x] Patched OnnxParser.refine_graph\n",
      "  [x] Patched Backend: Slice\n",
      "  [x] Patched Backend: Gather\n",
      "ESP-PPQ Runtime Patches Applied Successfully.\n"
     ]
    }
   ],
   "source": [
    "from esp_ppq_patch import apply_esp_ppq_patches\n",
    "apply_esp_ppq_patches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Preparation & Export\n",
    "We load the PyTorch checkpoint (`.pt`) and export it to ONNX. \n",
    "Critically, we apply `ESP_Attention` patches here to ensure the exported ONNX graph uses static reshaping, preventing runtime errors on the target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ESP-DL patches for export...\n",
      "Patched 2 Attention modules.\n",
      "Patched Detect module: <class 'ultralytics.nn.modules.head.Detect'>\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CPU (13th Gen Intel Core(TM) i7-13650HX)\n",
      ">> Fuse method blocked! Keeping all heads.\n",
      "YOLO26n summary (fused): 146 layers, 2,562,496 parameters, 0 gradients, 6.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo26n.pt' with input shape (16, 3, 512, 512) BCHW and output shape(s) ((16, 84, 64, 64), (16, 84, 32, 32), (16, 84, 16, 16), (16, 84, 64, 64), (16, 84, 32, 32), (16, 84, 16, 16)) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 13...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.3s, saved as 'c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\coco_640_s8_s3\\yolo26n_train.onnx' (9.9 MB)\n",
      "\n",
      "Export complete (2.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\u001b[0m\n",
      "Predict:         yolo predict task=detect model=c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\coco_640_s8_s3\\yolo26n_train.onnx imgsz=512 \n",
      "Validate:        yolo val task=detect model=c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\coco_640_s8_s3\\yolo26n_train.onnx imgsz=512 data=/home/lq/codes/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Export complete.\n",
      "Loading yolo26n.pt to extract metadata...\n",
      "Extracted Metadata: NC=80, RegMax=1, Stride=[8.0, 16.0, 32.0]\n"
     ]
    }
   ],
   "source": [
    "def extract_model_meta():\n",
    "    \"\"\"Dynamically extracts model metadata (NC, RegMax, etc.) from the PT checkpoint.\"\"\"\n",
    "    print(f\"Loading {QATConfig.PT_FILE} to extract metadata...\")\n",
    "    # We use ESP_YOLO here just to inspect, but standard YOLO would work too for this part\n",
    "    tmp_model = ESP_YOLO(QATConfig.PT_FILE)\n",
    "    \n",
    "    # Access the Detect Head (last layer)\n",
    "    detect_head = tmp_model.model.model[-1]\n",
    "    \n",
    "    # Derive input channels (ch) from the first layer of cv2\n",
    "    ch = [m[0].conv.in_channels for m in detect_head.cv2]\n",
    "    \n",
    "    meta = {\n",
    "        'nc': detect_head.nc,\n",
    "        'reg_max': detect_head.reg_max,\n",
    "        'stride': detect_head.stride,\n",
    "        'ch': ch\n",
    "    }\n",
    "    \n",
    "    if isinstance(meta['stride'], torch.Tensor):\n",
    "        meta['stride'] = meta['stride'].tolist()\n",
    "        \n",
    "    print(f\"Extracted Metadata: NC={meta['nc']}, RegMax={meta['reg_max']}, Stride={meta['stride']}\")\n",
    "    return meta\n",
    "\n",
    "def prepare_onnx():\n",
    "    \"\"\"Ensures the correct ONNX model exists with all patches applied.\"\"\"\n",
    "    try:\n",
    "        # Load using ESP_YOLO to enforce custom export logic\n",
    "        model = ESP_YOLO(QATConfig.PT_FILE)\n",
    "        \n",
    "        # Apply patches (Attention & Detect)\n",
    "        apply_export_patches(model)\n",
    "        \n",
    "        # Export\n",
    "        model.export(format=\"onnx\", opset=QATConfig.EXPORT_OPSET, simplify=True, \n",
    "                        imgsz=QATConfig.IMG_SZ, dynamic=QATConfig.EXPORT_DYNAMIC)\n",
    "        print(\"Export complete.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting model: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Run Preparation\n",
    "prepare_onnx()\n",
    "model_meta = extract_model_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantizer Initialization\n",
    "We load the ONNX graph and initialize the PPQ Quantizer.\n",
    "We also perform a graph analysis to separate the **Auxiliary Branch** (used for training guidance) from the **Main Branch** (used for inference). We disable quantization on the Aux branch to ensure gradients flow correctly without noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying auxiliary branch operators to disable quantization...\n",
      "Found 45 operators exclusive to auxiliary branch.\n"
     ]
    }
   ],
   "source": [
    "# Load Graph\n",
    "graph = load_onnx_graph(onnx_import_file=QATConfig.ONNX_PATH)\n",
    "\n",
    "# Identify and Disable Aux Layer Quantization\n",
    "output_names = list(graph.outputs.keys())\n",
    "aux_ops = set()\n",
    "if len(output_names) >= 6:\n",
    "    # Assuming order: [one2many_p3, ... one2one_p3, ...]\n",
    "    # Note: Custom exporter uses names one2many_p3 etc. which is explicitly handled here\n",
    "    aux_outputs = output_names[0:3]\n",
    "    main_outputs = output_names[3:6]\n",
    "    print(\"Identifying auxiliary branch operators to disable quantization...\")\n",
    "    aux_ops = get_exclusive_ancestors(graph, aux_outputs, main_outputs)\n",
    "    print(f\"Found {len(aux_ops)} operators exclusive to auxiliary branch.\")\n",
    "else:\n",
    "    print(\"WARNING: Graph output count < 6. Cannot separate aux/main branches.\")\n",
    "\n",
    "# Initialize Quantizer\n",
    "quantizer = PFL.Quantizer(platform=QATConfig.TARGET_PLATFORM, graph=graph)\n",
    "dispatching_table = PFL.Dispatcher(graph=graph, method=\"conservative\").dispatch(\n",
    "    quantizer.quant_operation_types\n",
    ")\n",
    "\n",
    "# Enforce FP32 for Aux ops and defaults\n",
    "for opname, platform in dispatching_table.items():\n",
    "    if platform == TargetPlatform.UNSPECIFIED:\n",
    "        dispatching_table[opname] = TargetPlatform(quantizer.target_platform)\n",
    "        \n",
    "for op in aux_ops:\n",
    "    if op.name in dispatching_table:\n",
    "        dispatching_table[op.name] = TargetPlatform.FP32\n",
    "\n",
    "# Apply Quantization\n",
    "for op in graph.operations.values():\n",
    "    quantizer.quantize_operation(op_name=op.name, platform=dispatching_table[op.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calibration\n",
    "Before training, we must calibrate the quantized parameters (scale/offset) using a representative dataset. This initializes the network in a good state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset at: C:\\Users\\orani\\OneDrive\\Desktop\\bilel\\Projects\\p_2025\\esp32p4dl_pip\\pytorch_lab\\version1\\yolov5\\datasets\\coco\\images\\train2017\n",
      "Fast image access  (ping: 0.10.1 ms, read: 1038.5659.0 MB/s, size: 155.2 KB)\n",
      "\u001b[KScanning C:\\Users\\orani\\OneDrive\\Desktop\\bilel\\Projects\\p_2025\\esp32p4dl_pip\\pytorch_lab\\version1\\yolov5\\datasets\\coco\\labels\\train2017.cache... 117266 images, 1021 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 118287/118287  0.0s\n",
      "Subsampling dataset to 0.5%: 591 samples\n",
      "\u001b[38;5;3m[WARNING][PPQ][2026-02-07 12:58:57]:  \u001b[mUnexpected input value of operation /model.11/Resize, recieving \"None\" at its input 1\n",
      "\u001b[38;5;3m[WARNING][PPQ][2026-02-07 12:58:57]:  \u001b[mUnexpected input value of operation /model.14/Resize, recieving \"None\" at its input 1\n",
      "Running Calibration Pipeline...\n",
      "[12:58:57] PPQ Quantize Simplify Pass Running ...         Finished.\n",
      "[12:58:57] PPQ Quantization Fusion Pass Running ...       Finished.\n",
      "[12:58:58] PPQ Parameter Quantization Pass Running ...    Finished.\n",
      "[12:58:58] PPQ Runtime Calibration Pass Running ...       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1):   0%|          | 0/32 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Op Execution Error: /model.10/m/m.0/attn/Reshape(Type: Reshape, Num of Input: 2, Num of Output: 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\executor\\torch.py:557\u001b[0m, in \u001b[0;36mTorchExecutor.__forward\u001b[1;34m(self, inputs, executing_order, output_names, hooks)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# forward and collecting result\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43moperation_forward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executing_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m [outputs]\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\executor\\op\\torch\\default.py:824\u001b[0m, in \u001b[0;36mReshape_forward\u001b[1;34m(op, values, ctx, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m shape \u001b[38;5;241m=\u001b[39m [shape[i]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(shape[i], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape))]\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 2, 128, 256]' is invalid for input of size 1433600",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 22\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Calibration Pipeline...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m PFL\u001b[38;5;241m.\u001b[39mPipeline([\n\u001b[0;32m     14\u001b[0m     QuantizeSimplifyPass(),\n\u001b[0;32m     15\u001b[0m     QuantizeFusionPass(activation_type\u001b[38;5;241m=\u001b[39mquantizer\u001b[38;5;241m.\u001b[39mactivation_fusion_types),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     QuantAlignmentPass(elementwise_alignment\u001b[38;5;241m=\u001b[39mQATConfig\u001b[38;5;241m.\u001b[39mQUANT_ALIGNMENT),\n\u001b[0;32m     20\u001b[0m ])\n\u001b[1;32m---> 22\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalib_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQATConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCALIB_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQATConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcali_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\quantization\\optim\\base.py:88\u001b[0m, in \u001b[0;36mQuantizationOptimizationPipeline.optimize\u001b[1;34m(self, graph, verbose, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(graph, BaseGraph):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameter 1 should be an instance of PPQ BaseGraph when calling optim pass, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhowever \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(graph)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was given.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m optim_pass\u001b[38;5;241m.\u001b[39moptimize(graph\u001b[38;5;241m=\u001b[39mgraph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\core\\defs.py:60\u001b[0m, in \u001b[0;36mempty_ppq_cache.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m empty_cache()  \u001b[38;5;66;03m# torch.cuda.empty_cache might requires a sync of all cuda device.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()  \u001b[38;5;66;03m# empty memory.\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\quantization\\optim\\calibration.py:199\u001b[0m, in \u001b[0;36mRuntimeCalibrationPass.optimize\u001b[1;34m(self, graph, dataloader, executor, calib_steps, collate_fn, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     hooks[op_name] \u001b[38;5;241m=\u001b[39m observer\u001b[38;5;241m.\u001b[39mhook\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# ready for calibration\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# hook forward function, let observers take effects.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCalibration Progress(Phase 1)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# render calibration result.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, observer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\quantization\\optim\\calibration.py:133\u001b[0m, in \u001b[0;36mRuntimeCalibrationPass.calibrate\u001b[1;34m(self, desc, dataloader, executor, hooks, output_names)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collate_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collate_fn(data)\n\u001b[1;32m--> 133\u001b[0m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m progressing_bar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    135\u001b[0m calib_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\executor\\torch.py:405\u001b[0m, in \u001b[0;36mTorchExecutor.forward\u001b[1;34m(self, inputs, output_names, hooks)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m     hooks: Dict[\u001b[38;5;28mstr\u001b[39m, RuntimeHook] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    371\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward function of this executor.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    Notice this forward function will never store and compute gradients.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m        List[torch.Tensor]: [executing result, list of tensor objects.]\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecuting_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executing_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\esp-ppq-yolo26\\esp_ppq\\executor\\torch.py:602\u001b[0m, in \u001b[0;36mTorchExecutor.__forward\u001b[1;34m(self, inputs, executing_order, output_names, hooks)\u001b[0m\n\u001b[0;32m    600\u001b[0m             result_collector[output_names\u001b[38;5;241m.\u001b[39mindex(output_var\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;241m=\u001b[39m outputs[output_idx]\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOp Execution Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(operation)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# remove useless value(runtime clear).\u001b[39;00m\n\u001b[0;32m    605\u001b[0m visited_op\u001b[38;5;241m.\u001b[39mappend(operation)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Op Execution Error: /model.10/m/m.0/attn/Reshape(Type: Reshape, Num of Input: 2, Num of Output: 1)"
     ]
    }
   ],
   "source": [
    "# Data Loaders\n",
    "data_cfg = check_det_dataset(QATConfig.DATA_YAML_FILE)\n",
    "cali_loader = get_calibration_loader(data_cfg)\n",
    "train_loader = get_train_loader(data_cfg)\n",
    "\n",
    "# Tracing\n",
    "executor = TorchExecutor(graph=graph)\n",
    "dummy_input = torch.zeros([1, 3, QATConfig.IMG_SZ, QATConfig.IMG_SZ]).to(QATConfig.DEVICE)\n",
    "executor.tracing_operation_meta(inputs=dummy_input)\n",
    "\n",
    "# Calibration Pipeline\n",
    "print(\"Running Calibration Pipeline...\")\n",
    "pipeline = PFL.Pipeline([\n",
    "    QuantizeSimplifyPass(),\n",
    "    QuantizeFusionPass(activation_type=quantizer.activation_fusion_types),\n",
    "    ParameterQuantizePass(),\n",
    "    RuntimeCalibrationPass(method=QATConfig.QUANT_CALIB_METHOD),\n",
    "    PassiveParameterQuantizePass(clip_visiblity=QuantizationVisibility.EXPORT_WHEN_ACTIVE),\n",
    "    QuantAlignmentPass(elementwise_alignment=QATConfig.QUANT_ALIGNMENT),\n",
    "])\n",
    "\n",
    "pipeline.optimize(\n",
    "    calib_steps=QATConfig.CALIB_STEPS,\n",
    "    collate_fn=(lambda x: x.type(torch.float).to(QATConfig.DEVICE)),\n",
    "    graph=graph,\n",
    "    dataloader=cali_loader,\n",
    "    executor=executor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Validation (Check PTQ Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Trainer for Baseline Check...\n",
      "Loading YOLOv26n model in Trainer to access correct Loss function...\n",
      "Initializing Persistent Validator (reusing dataloader)...\n",
      "Running Baseline Validation on Quantized Graph...\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 176.5117.9 MB/s, size: 104.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\orani\\OneDrive\\Desktop\\bilel\\Projects\\p_2025\\esp32p4dl_pip\\pytorch_lab\\version1\\yolov5\\datasets\\coco\\labels\\val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5000/5000  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 209/209 1.3it/s 2:37<0.6s\n",
      "                   all       5000      36335      0.604      0.444      0.492      0.342\n",
      "\n",
      "--- Baseline Results ---\n",
      "PTQ mAP50-95: 0.342\n",
      "Target: This serves as the baseline. QAT will now attempt to improve this score.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer just for evaluation\n",
    "print(\"Initializing Trainer for Baseline Check...\")\n",
    "trainer = QATTrainer(graph=graph, model_meta=model_meta, device=QATConfig.DEVICE)\n",
    "\n",
    "# Run validation on the graph in its current state (after Calibration/PTQ, before Training)\n",
    "print(\"Running Baseline Validation on Quantized Graph...\")\n",
    "ptq_mAP = trainer.eval()\n",
    "\n",
    "print(f\"\\n--- Baseline Results ---\")\n",
    "print(f\"PTQ mAP50-95: {ptq_mAP:.3f}\")\n",
    "print(f\"Target: This serves as the baseline. QAT will now attempt to improve this score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. QAT Training Loop\n",
    "We now fine-tune the quantized model. The `QATTrainer` handles the forward pass through the quantized graph (simulated by PPQ) and the backward pass to update weights.\n",
    "\n",
    "Note: The validation step uses our `QuantizedModelValidator` which manually decodes the raw graph outputs using the metadata extracted earlier (`NC`, `RegMax`, `Estride`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting QAT Training...\n",
      "\n",
      "--- Epoch 1/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 43/43 [00:38<00:00,  1.12it/s, loss=6.7541] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 36.5569\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 209/209 2.1it/s 1:40<0.5ss\n",
      "                   all       5000      36335      0.609      0.463      0.506      0.357\n",
      "Epoch: 1, mAP50-95: 0.357\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\coco_640_s8_s3...\n",
      "\n",
      "--- Epoch 2/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 43/43 [00:37<00:00,  1.13it/s, loss=6.5141] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 35.3756\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 209/209 2.0it/s 1:43<0.6ss\n",
      "                   all       5000      36335      0.608      0.472      0.515      0.364\n",
      "Epoch: 2, mAP50-95: 0.364\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\coco_640_s8_s3...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting QAT Training...\")\n",
    "\n",
    "if not os.path.exists(QATConfig.ESPDL_OUTPUT_DIR):\n",
    "    os.makedirs(QATConfig.ESPDL_OUTPUT_DIR)\n",
    "\n",
    "best_mAP = 0\n",
    "for epoch in range(QATConfig.EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{QATConfig.EPOCHS} ---\")\n",
    "    \n",
    "    # Train Epoch\n",
    "    trainer.epoch(train_loader)\n",
    "    \n",
    "    # Validate\n",
    "    current_mAP = trainer.eval()\n",
    "    print(f\"Epoch: {epoch+1}, mAP50-95: {current_mAP:.3f}\")\n",
    "    \n",
    "    if current_mAP > best_mAP:\n",
    "        best_mAP = current_mAP\n",
    "        print(f\"New best mAP! Saving to {QATConfig.ESPDL_OUTPUT_DIR}...\")\n",
    "        \n",
    "        # Save Native Graph using the new helper method\n",
    "        trainer.save_graph(os.path.join(QATConfig.ESPDL_OUTPUT_DIR, \"Best_yolo26n.native\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Best Graph...\n",
      "Best Graph Reloaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Best Graph back into memory at the end\n",
    "print(\"Reloading Best Graph...\")\n",
    "trainer.load_graph(os.path.join(QATConfig.ESPDL_OUTPUT_DIR, \"Best_yolo26n.native\"))\n",
    "# Update global graph \n",
    "graph = trainer.graph \n",
    "print(\"Best Graph Reloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Best Graph...\n",
      "Preparing Graph for Inference...\n",
      "Removing Aux Heads: ['one2many_p3', 'one2many_p4', 'one2many_p5']\n",
      "Starting Safe Pruning Procedure...\n",
      "Pruning Finished. Total Rounds: 11\n",
      "Splitting one2one_p3 at Source Concat (/model.23/Concat_3)...\n",
      "  -> Created one2one_p3_box and one2one_p3_cls\n",
      "Splitting one2one_p4 at Source Concat (/model.23/Concat_4)...\n",
      "  -> Created one2one_p4_box and one2one_p4_cls\n",
      "Splitting one2one_p5 at Source Concat (/model.23/Concat_5)...\n",
      "  -> Created one2one_p5_box and one2one_p5_cls\n",
      "Updating Graph Output Order...\n",
      "Registered 6 split outputs.\n",
      "Starting Safe Pruning Procedure...\n",
      "Pruning Finished. Total Rounds: 2\n",
      "Final Graph Outputs: ['one2one_p3_box', 'one2one_p4_box', 'one2one_p5_box', 'one2one_p3_cls', 'one2one_p4_cls', 'one2one_p5_cls']\n",
      "Exporting Split Inference Model to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\coco_640_s8_s3\\yolo26n_640_s8_s3.espdl...\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_1 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_1 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_1 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_1 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_87 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_90 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_92 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_95 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_97 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_100 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_102 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_105 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 12:54:44]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "Export Done!\n"
     ]
    }
   ],
   "source": [
    "import esp_ppq.lib as PFL\n",
    "from config import QATConfig\n",
    "import os\n",
    "from esp_ppq.api import load_native_graph\n",
    "from esp_ppq.IR import BaseGraph  \n",
    "\n",
    "# --- Helper Function: Robust Graph Pruning ---\n",
    "def prune_graph_safely(graph: BaseGraph) -> BaseGraph:\n",
    "    \"\"\"\n",
    "    Robust pruning function for ESP-PPQ graphs.\n",
    "    Safely removes disconnected operations and unused variables.\n",
    "    \"\"\"\n",
    "    print(\"Starting Safe Pruning Procedure...\")\n",
    "    round_count = 0\n",
    "    while True:\n",
    "        this_round_op_removed = 0\n",
    "        this_round_var_removed = 0\n",
    "        \n",
    "        # A. Find Dead Ops\n",
    "        dead_ops = []\n",
    "        for op in list(graph.operations.values()):\n",
    "            is_output = any(var.name in graph.outputs for var in op.outputs)\n",
    "            has_consumers = any(len(var.dest_ops) > 0 for var in op.outputs)\n",
    "            \n",
    "            if not is_output and not has_consumers:\n",
    "                dead_ops.append(op)\n",
    "        \n",
    "        # Remove Dead Ops Safely\n",
    "        for op in dead_ops:\n",
    "            for var in list(op.inputs):\n",
    "                 op.inputs.remove(var)\n",
    "                 if op in var.dest_ops:\n",
    "                     var.dest_ops.remove(op)\n",
    "            graph.remove_operation(op, keep_coherence=False)\n",
    "            this_round_op_removed += 1\n",
    "            \n",
    "        # B. Find Dead Variables\n",
    "        dead_vars = []\n",
    "        for var in list(graph.variables.values()):\n",
    "            is_input = var.name in graph.inputs\n",
    "            is_output = var.name in graph.outputs\n",
    "            if is_input or is_output: continue\n",
    "            \n",
    "            if len(var.dest_ops) == 0:\n",
    "                dead_vars.append(var)\n",
    "                 \n",
    "        # Remove Dead Variables\n",
    "        for var in dead_vars:\n",
    "            if var.name in graph.variables:\n",
    "                graph.variables.pop(var.name)\n",
    "                this_round_var_removed += 1\n",
    "        \n",
    "        round_count += 1\n",
    "        if this_round_op_removed == 0 and this_round_var_removed == 0:\n",
    "            break\n",
    "            \n",
    "    print(f\"Pruning Finished. Total Rounds: {round_count}\")\n",
    "    return graph\n",
    "\n",
    "# --- MAIN LOGIC: Split Outputs at Concat Source ---\n",
    "\n",
    "print(\"Reloading Best Graph...\")\n",
    "native_graph_path = os.path.join(QATConfig.ESPDL_OUTPUT_DIR, \"Best_yolo26n.native\")\n",
    "graph = load_native_graph(import_file=native_graph_path)\n",
    "\n",
    "print(\"Preparing Graph for Inference...\")\n",
    "\n",
    "# 1. Remove Aux Heads First (Cleanup)\n",
    "output_names = list(graph.outputs.keys())\n",
    "if len(output_names) >= 6:\n",
    "    aux_heads = output_names[0:3] \n",
    "    print(f\"Removing Aux Heads: {aux_heads}\")\n",
    "    for name in aux_heads:\n",
    "        if name in graph.outputs:\n",
    "            graph.outputs.pop(name)\n",
    "    prune_graph_safely(graph)\n",
    "\n",
    "# 2. Apply Splitting Strategy\n",
    "targets = [\"one2one_p3\", \"one2one_p4\", \"one2one_p5\"]\n",
    "collected_outputs = {}\n",
    "\n",
    "for target_name in targets:\n",
    "    if target_name in graph.outputs:\n",
    "        original_output_var = graph.variables[target_name]\n",
    "        producer = original_output_var.source_op \n",
    "        \n",
    "        if producer and producer.type == \"Concat\":\n",
    "            print(f\"Splitting {target_name} at Source Concat ({producer.name})...\")\n",
    "            \n",
    "            box_var = None\n",
    "            cls_var = None\n",
    "            \n",
    "            # Inspect Concat inputs to find Box(4) and Cls(80)\n",
    "            for input_var in producer.inputs:\n",
    "                dims = input_var.shape\n",
    "                if dims is not None:\n",
    "                    if 4 in dims: box_var = input_var\n",
    "                    elif 80 in dims: cls_var = input_var\n",
    "            \n",
    "            if box_var and cls_var:\n",
    "                # Rename Scheme: Suffix per Request\n",
    "                pair_config = [\n",
    "                    (box_var, f\"{target_name}_box\"),  # e.g. one2one_p3_box\n",
    "                    (cls_var, f\"{target_name}_cls\")   # e.g. one2one_p3_cls\n",
    "                ]\n",
    "                \n",
    "                for var, new_name in pair_config:\n",
    "                    old_name = var.name\n",
    "                    \n",
    "                    # Robust Renaming (Modify Private + Registry)\n",
    "                    if old_name in graph.variables:\n",
    "                        graph.variables.pop(old_name)\n",
    "                    \n",
    "                    var._name = new_name\n",
    "                    graph.variables[new_name] = var\n",
    "                    \n",
    "                    collected_outputs[new_name] = var\n",
    "                \n",
    "                # Update Graph Outputs: Remove old name\n",
    "                graph.outputs.pop(target_name)\n",
    "                \n",
    "                # Properly Remove Concat Op\n",
    "                graph.remove_operation(producer, keep_coherence=False)\n",
    "                # Unlink inputs\n",
    "                for var in producer.inputs:\n",
    "                    if producer in var.dest_ops:\n",
    "                        var.dest_ops.remove(producer)\n",
    "\n",
    "                print(f\"  -> Created {pair_config[0][1]} and {pair_config[1][1]}\")\n",
    "            else:\n",
    "                print(f\"ERROR: Shape mismatch for {target_name}\")\n",
    "        else:\n",
    "             print(f\"WARNING: Source for {target_name} is not Concat.\")\n",
    "\n",
    "# 3. Register New Outputs in Strict Order (Box Group then Cls Group)\n",
    "final_output_list = [\n",
    "    \"one2one_p3_box\", \"one2one_p4_box\", \"one2one_p5_box\",\n",
    "    \"one2one_p3_cls\", \"one2one_p4_cls\", \"one2one_p5_cls\"\n",
    "]\n",
    "\n",
    "print(\"Updating Graph Output Order...\")\n",
    "graph.outputs.clear() # Enforce strict order\n",
    "count_added = 0\n",
    "for name in final_output_list:\n",
    "    if name in collected_outputs:\n",
    "        graph.outputs[name] = collected_outputs[name]\n",
    "        count_added += 1\n",
    "\n",
    "print(f\"Registered {count_added} split outputs.\")\n",
    "\n",
    "# 4. Final Prune\n",
    "prune_graph_safely(graph)\n",
    "\n",
    "print(f\"Final Graph Outputs: {list(graph.outputs.keys())}\") \n",
    "\n",
    "# 5. Export\n",
    "inference_export_path = os.path.join(QATConfig.ESPDL_OUTPUT_DIR, f\"yolo26n_{QATConfig.IMG_SZ}_s8_{PLATFORM}.espdl\")\n",
    "print(f\"Exporting Split Inference Model to {inference_export_path}...\")\n",
    "\n",
    "exporter = PFL.Exporter(platform=QATConfig.TARGET_PLATFORM)\n",
    "exporter.export(inference_export_path, graph=graph)\n",
    "print(\"Export Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
