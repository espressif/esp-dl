{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv26 Quantization Aware Training (QAT)\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete Quantization Aware Training (QAT) pipeline for **YOLOv26**, tailored for deployment on **ESP32-P4** (via ESP-DL and ESP-PPQ).\n",
    "\n",
    "### Key Features of YOLOv26\n",
    "YOLOv26 represents an evolution in the YOLO architecture focusing on efficiency and end-to-end deployment.\n",
    "- **NMS-Free Prediction**: Utilizes a dual-head architecture (One-to-Many for training signal, One-to-One for inference), eliminating the need for Non-Maximum Suppression (NMS) during inference.\n",
    "- **RegMax=1**: Unlike YOLOv8 (RegMax=16) which uses Distribution Focal Loss (DFL), YOLOv26 uses direct regression (`RegMax=1`), reducing output channel complexity and post-processing overhead.\n",
    "- **Efficient Attention**: Incorporates attention mechanisms (e.g., C2PSA) optimized for low-latency edge devices.\n",
    "\n",
    "### Optimizer Choice: SGD vs MuoSGD\n",
    "For this QAT pipeline, we have chosen **SGD (Stochastic Gradient Descent)** over **MuoSGD**.\n",
    "- **Reason**: We involve only a small fine-tuning step on a model that is already pretrained and calibrated.\n",
    "- **Simplicity**: Since the model starts in a good state, we do not need the additional complexity of MuoSGD (which is designed for more aggressive topology changes or from-scratch quantization training). Standard SGD is sufficient and effective for this task.\n",
    "\n",
    "### QAT Workflow Specifics\n",
    "This pipeline addresses specific challenges in quantizing YOLOv26 for embedded targets:\n",
    "1.  **Custom Export Patches**: \n",
    "    - Patches `Attention` modules to use static reshaping (`view(-1, ...)`), ensuring compatibility with ESP-DL's static graph compiler.\n",
    "    - Preserves all 6 output heads (3x Aux, 3x Main) during QAT to calculate accurate loss, while enabling `dynamic=False` export for final deployment.\n",
    "2.  **Sensitive Layer Analysis**: Automatically identifies and disables quantization for the Auxiliary Branch to stabilize training.\n",
    "3.  **PPQ Integration**: Uses the internal quantization pipeline (Simplify -> Fusion -> Parameter Quantize -> Calibration -> Finetuning) before starting the QAT loop.\n",
    "4.  **Custom Validator**: A dedicated validator that mimics the Quantized Graph execution to report real on-target mAP metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: esp-ppq==1.2.4 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: onnx==1.17.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: onnxruntime>=1.19.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 3)) (1.19.2)\n",
      "Requirement already satisfied: torch>=2.4.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 4)) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.19.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 5)) (0.23.0+cu126)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: ultralytics==8.4.7 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 7)) (8.4.7)\n",
      "Requirement already satisfied: onnxsim>=0.4.36 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from -r requirements.txt (line 8)) (0.4.36)\n",
      "Requirement already satisfied: cryptography>=45.0.4 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (46.0.2)\n",
      "Requirement already satisfied: flatbuffers>=25.2.10 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (25.2.10)\n",
      "Requirement already satisfied: setuptools>=75.3.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (78.1.0)\n",
      "Requirement already satisfied: toml in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from esp-ppq==1.2.4->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnx==1.17.0->-r requirements.txt (line 2)) (4.25.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (3.9.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (5.9.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (1.36.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from ultralytics==8.4.7->-r requirements.txt (line 7)) (2.0.18)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxruntime>=1.19.0->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxruntime>=1.19.0->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxruntime>=1.19.0->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from torch>=2.4.0->-r requirements.txt (line 4)) (2024.6.1)\n",
      "Requirement already satisfied: rich in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from onnxsim>=0.4.36->-r requirements.txt (line 8)) (13.9.4)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from cryptography>=45.0.4->esp-ppq==1.2.4->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (6.5.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from polars>=0.20.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.36.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from sympy->onnxruntime>=1.19.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from tqdm>=4.67.1->esp-ppq==1.2.4->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from coloredlogs->onnxruntime>=1.19.0->-r requirements.txt (line 3)) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from jinja2->torch>=2.4.0->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from rich->onnxsim>=0.4.36->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from rich->onnxsim>=0.4.36->-r requirements.txt (line 8)) (2.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from cffi>=2.0.0->cryptography>=45.0.4->esp-ppq==1.2.4->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.19.0->-r requirements.txt (line 3)) (3.5.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->onnxsim>=0.4.36->-r requirements.txt (line 8)) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.4.7->-r requirements.txt (line 7)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§± Step: Download & Prepare LEGO Minifigures Dataset\n",
    "To showcase the **NMS-Free YOLO26n** capabilities, we are using the LEGO Minifigures dataset. \n",
    "This dataset is ideal because:\n",
    "* **High Density:** Multiple small objects in close proximity.\n",
    "* **Vibrant Colors:** Excellent for testing Int8 Quantization accuracy.\n",
    "* **NMS-Free Test:** Directly regressing bounding boxes for similar-looking figures.\n",
    "\n",
    "**Dataset Source:** [Lego Minifigures on Roboflow](https://universe.roboflow.com/hexhewwie/hex-lego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\orani\\appdata\\roaming\\python\\python39\\site-packages (1.2.13)\n",
      "Requirement already satisfied: certifi in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (2025.8.3)\n",
      "Requirement already satisfied: idna==3.7 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (3.9.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\orani\\appdata\\roaming\\python\\python39\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (10.4.0)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.5.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib->roboflow) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib->roboflow) (4.55.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib->roboflow) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from matplotlib->roboflow) (6.5.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from requests->roboflow) (3.3.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"xxxxxxxxxxxxxx\")\n",
    "project = rf.workspace(\"hexhewwie\").project(\"hex-lego\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov5\", location=\"lego_data\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Fine-Tuning YOLO26n on LEGO Data\n",
    "We will now perform transfer learning. We start with the pre-trained `yolo26n.pt` weights and fine-tune them on our LEGO dataset. \n",
    "* **Model:** YOLO26n (NMS-Free)\n",
    "* **Epochs:** 50 (Adjustable)\n",
    "* **Image Size:** 512 (Matching your ESP32-P4 optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data.yaml paths updated!\n",
      "New 'path' is: lego_data\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_path = 'lego_data/data.yaml'\n",
    "\n",
    "# 1. Read the current yaml\n",
    "with open(yaml_path, 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# 2. Fix the path logic\n",
    "# We set 'path' to the absolute current directory or just '.'\n",
    "data['path'] = 'lego_data' \n",
    "# Ensure the sub-paths don't repeat the folder name\n",
    "data['train'] = 'train/images'\n",
    "data['val'] = 'valid/images'\n",
    "data['test'] = 'test/images'\n",
    "\n",
    "# 3. Write it back\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "print(\"âœ… data.yaml paths updated!\")\n",
    "print(f\"New 'path' is: {data['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.4.12 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=48, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=lego_data/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train7, nbs=64, nms=False, opset=None, optimize=False, optimizer=MuSGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "WARNING The COMET_MODE environment variable is deprecated. Please use COMET_START_ONLINE to set the Comet experiment mode. To start an offline Comet experiment, use 'export COMET_START_ONLINE=0'. If COMET_START_ONLINE is not set or is set to '1', an online Comet experiment will be created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Failed to create Comet experiment, reason: ValueError('Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Comet installed but not initialized correctly, not logging this run. Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY \n",
      "Overriding model.yaml nc=80 with nc=28\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5, 3, True]        \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    119808  ultralytics.nn.modules.block.C3k2            [384, 128, 1, True]           \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     34304  ultralytics.nn.modules.block.C3k2            [256, 64, 1, True]            \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     95232  ultralytics.nn.modules.block.C3k2            [192, 128, 1, True]           \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    463104  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True, 0.5, True]\n",
      " 23        [16, 19, 22]  1    252096  ultralytics.nn.modules.head.Detect           [28, 1, True, [64, 128, 256]] \n",
      "YOLO26n summary: 260 layers, 2,514,720 parameters, 2,514,720 gradients, 5.8 GFLOPs\n",
      "\n",
      "Transferred 606/708 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 316.6160.5 MB/s, size: 21.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\lego_data\\train\\labels.cache... 7408 images, 3694 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7408/7408  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 125.544.3 MB/s, size: 20.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\lego_data\\valid\\labels.cache... 628 images, 302 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 628/628  0.0s\n",
      "Plotting labels to C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.001, momentum=0.937) with parameter groups 114 weight(decay=0.0), 126 weight(decay=0.000375), 126 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/40       5.8G      1.055      6.124   0.009914         20        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.0it/s 1:180.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 1.2it/s 6.1s0.4ss\n",
      "                   all        628       1292    0.00974      0.248     0.0155     0.0132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/40      5.63G      1.046      4.865   0.009452         99        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.4it/s 1:050.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.269      0.147      0.085     0.0635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/40      5.35G       1.04       3.79   0.009684         48        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.4it/s 1:050.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.318      0.289      0.227      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/40      5.75G      1.015       3.15   0.009351         46        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.3it/s 1:080.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        628       1292      0.431      0.418       0.39        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/40      5.64G     0.9785       2.73   0.009038         42        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.1it/s 1:130.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.6it/s 2.7s0.4s\n",
      "                   all        628       1292       0.43      0.487      0.453      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/40      5.96G     0.9816      2.424   0.008928         42        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.0it/s 1:180.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.3it/s 3.0s0.5s\n",
      "                   all        628       1292      0.525      0.486      0.509      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/40      5.86G     0.9734      2.186   0.008828         17        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.0it/s 1:170.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.515      0.513      0.532      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/40      6.06G     0.9591      1.957   0.008579         34        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.3it/s 1:060.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.554      0.555      0.578      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/40      5.92G     0.9475      1.782   0.008434         56        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.3it/s 1:080.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        628       1292      0.651      0.503      0.599       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/40      5.74G     0.9368      1.594   0.008268        126        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.2it/s 1:100.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.7it/s 2.6s0.4s\n",
      "                   all        628       1292      0.653      0.619      0.667       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/40       5.6G     0.9261      1.474   0.008219         30        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.9it/s 1:200.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.3s0.5s\n",
      "                   all        628       1292      0.657      0.591      0.667      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/40       5.7G     0.9118      1.345   0.008081         40        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.9it/s 1:230.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.4s0.4s\n",
      "                   all        628       1292      0.638      0.627      0.689      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/40      5.29G     0.9071      1.247   0.007973         46        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.4it/s 1:050.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.718      0.609      0.691      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/40      5.65G     0.9061      1.225   0.008146        104        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.6it/s 1:350.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.4s0.5s\n",
      "                   all        628       1292      0.728      0.626      0.718      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/40       5.2G     0.8952       1.15   0.007908         44        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.2it/s 1:120.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.4s0.4s\n",
      "                   all        628       1292      0.757      0.635      0.722      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/40      5.45G     0.8816      1.102   0.007698         52        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.1it/s 1:140.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.0it/s 3.6s0.6ss\n",
      "                   all        628       1292       0.73      0.643      0.725      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/40      5.68G       0.88      1.014   0.007715         67        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.8it/s 1:280.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.764      0.674      0.751      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/40      5.82G     0.8713      0.976   0.007804         32        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.4it/s 1:050.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.803      0.655      0.764       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/40      6.53G     0.8663     0.9406   0.007611         36        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.0it/s 1:170.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.4it/s 2.9s0.5s\n",
      "                   all        628       1292      0.807      0.675      0.778      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/40       6.4G     0.8517     0.9022   0.007673         30        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.9it/s 1:200.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.4s0.4s\n",
      "                   all        628       1292      0.766      0.696      0.773       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/40      5.53G     0.8654     0.8928   0.007454         39        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.3it/s 1:060.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.3s0.4s\n",
      "                   all        628       1292      0.764      0.712      0.786      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/40      5.49G     0.8558     0.8535   0.007449         19        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.3it/s 1:070.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.5s0.4s\n",
      "                   all        628       1292      0.789      0.701      0.793      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/40      5.96G     0.8405     0.8134   0.007421         36        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.2it/s 1:110.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.7it/s 2.6s0.4s\n",
      "                   all        628       1292      0.797      0.691      0.793      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/40         6G     0.8358     0.8031   0.007251         44        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.0it/s 1:180.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.2it/s 3.2s0.5s\n",
      "                   all        628       1292      0.824      0.709      0.798      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/40      5.66G     0.8263     0.7831   0.007188         20        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.6it/s 1:380.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        628       1292      0.837      0.681      0.784      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/40      6.78G      0.817     0.7596    0.00719         27        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:500.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.783      0.728        0.8      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/40      5.97G     0.8229     0.7586   0.007134         42        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.3it/s 1:550.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.3s0.5ss\n",
      "                   all        628       1292        0.8      0.741      0.811      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/40      6.04G      0.821     0.7328   0.007099         59        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:540.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.809      0.745      0.815      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/40      5.68G     0.7985     0.6989   0.006916         82        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.3it/s 1:560.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.782      0.759      0.816      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/40      6.21G     0.8045      0.701   0.007047         26        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:480.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        628       1292      0.836      0.728      0.817       0.67\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/40      5.69G     0.7235     0.5492   0.007106         23        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.5it/s 1:450.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.3s0.5s\n",
      "                   all        628       1292       0.83      0.723      0.819      0.668\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/40      5.77G     0.7035     0.5206   0.006915         47        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:520.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.867      0.706      0.814       0.67\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/40      5.55G     0.6931     0.5009   0.006712         20        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:540.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.0it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.862      0.714      0.819      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/40      5.75G     0.6746     0.4812   0.006721         12        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.7it/s 1:340.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.3s0.5ss\n",
      "                   all        628       1292      0.867      0.721      0.819      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/40      6.16G     0.6793     0.4671   0.006677         99        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:530.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.2it/s 3.3s0.5ss\n",
      "                   all        628       1292      0.882      0.723      0.821       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/40      5.51G     0.6748      0.455   0.006412         21        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.5it/s 1:450.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.886      0.711      0.825      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/40      5.42G     0.6575     0.4416   0.006438         24        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.3it/s 1:560.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.0it/s 3.5s0.6ss\n",
      "                   all        628       1292      0.889      0.716      0.827      0.687\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/40      6.15G     0.6638     0.4473   0.006364         18        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.4it/s 1:540.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.0it/s 3.5s0.5ss\n",
      "                   all        628       1292      0.852      0.729      0.823      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/40      5.65G     0.6608     0.4374   0.006231         24        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.5it/s 1:450.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.0it/s 3.4s0.5ss\n",
      "                   all        628       1292      0.868      0.716      0.822      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/40      5.83G     0.6443     0.4184   0.006233         19        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 1.9it/s 1:200.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.3s0.4s\n",
      "                   all        628       1292       0.86      0.732      0.826       0.69\n",
      "\n",
      "40 epochs completed in 1.017 hours.\n",
      "Optimizer stripped from C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7\\weights\\best.pt...\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO26n summary (fused): 122 layers, 2,380,296 parameters, 0 gradients, 5.2 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.8it/s 1.8s0.3s\n",
      "                   all        628       1292      0.863      0.732      0.827       0.69\n",
      "              1x1_blue         10         27       0.96      0.881      0.934      0.753\n",
      "             1x1_green         17         65      0.833      0.631      0.796      0.604\n",
      "              1x1_pink         16         67      0.805      0.552      0.604      0.512\n",
      "               1x1_red         17         26      0.926      0.923      0.956       0.79\n",
      "            1x1_yellow         12         33      0.784      0.771      0.886      0.705\n",
      "              2x1_blue          5         18       0.79      0.419      0.482      0.361\n",
      "             2x1_green          8         30          1      0.419      0.604      0.404\n",
      "              2x1_pink          6         27      0.588      0.264      0.447      0.306\n",
      "               2x1_red          4         12      0.638      0.298      0.442      0.365\n",
      "            2x1_yellow          8         17      0.892      0.647      0.759      0.634\n",
      "              2x2_blue         14         27      0.924      0.852      0.939      0.779\n",
      "             2x2_green         23         58      0.872      0.828      0.893      0.665\n",
      "              2x2_pink         28        131      0.954       0.32      0.902      0.725\n",
      "               2x2_red         45        108      0.955      0.722       0.78      0.623\n",
      "            2x2_yellow         27         78      0.888      0.817      0.923      0.757\n",
      "              2x3_blue         13         21      0.936      0.952      0.982      0.891\n",
      "             2x3_green         11         14      0.561      0.714      0.744      0.679\n",
      "              2x3_pink          8         32      0.881      0.906      0.963      0.847\n",
      "               2x3_red         16         22      0.912      0.909      0.925      0.812\n",
      "            2x3_yellow         10         21      0.846      0.952      0.982      0.907\n",
      "              2x4_blue         32        154      0.923      0.961      0.978      0.863\n",
      "             2x4_green         26         77      0.878      0.766      0.841      0.725\n",
      "              2x4_pink         13         29          1      0.994      0.995      0.887\n",
      "               2x4_red         40         85       0.95      0.897      0.959      0.831\n",
      "            2x4_yellow         22        113      0.879      0.903      0.949      0.833\n",
      "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\runs\\detect\\train7\u001b[0m\n",
      "âœ… Training complete! Weights saved in 'runs/detect/train/weights/best.pt'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "# Disable Comet, WandB and other loggers to keep output clean\n",
    "os.environ[\"COMET_MODE\"] = \"disabled\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "# 1. Load the YOLO26n model\n",
    "model = YOLO('yolo26n.pt') \n",
    "\n",
    "# 2. Start Fine-Tuning\n",
    "# We use 'lego_data/data.yaml' which was created by the Roboflow download.\n",
    "results = model.train(\n",
    "    data=\"lego_data/data.yaml\",   # Path to the LEGO data config\n",
    "    epochs=40,                   # 10 epochs for fine-tuning\n",
    "    imgsz=512,                   # Optimized size for ESP32-P4\n",
    "    batch=48,                    # Adjust based on your GPU memory\n",
    "    device=0,                    # Use '0' for GPU\n",
    "    plots=True,                  # Generates training charts\n",
    "    \n",
    "    # --- Learning Rate Adjustments ---\n",
    "    optimizer='MuSGD',\n",
    "    lr0=0.001,                   # Initial learning rate (Standard fine-tuning)\n",
    "    lrf=0.01,                    # Final learning rate (lr0 * lrf)\n",
    "    warmup_epochs=2.0            # Slowly ramp up for 2 epochs to stabilize\n",
    ")\n",
    "\n",
    "print(\"âœ… Training complete! Weights saved in 'runs/detect/trainx/weights/best.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Success! Your LEGO model is saved as: c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\yolo26n_lego.pt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 1. Find the latest 'best.pt' weights from your training runs\n",
    "# This looks in all 'train*' folders and picks the most recent one\n",
    "weight_files = glob(\"runs/detect/train*/weights/best.pt\")\n",
    "\n",
    "if weight_files:\n",
    "    # Get the most recent folder based on creation time\n",
    "    latest_weights = max(weight_files, key=os.path.getctime)\n",
    "    \n",
    "    # 2. Define your destination name\n",
    "    destination = \"yolo26n_lego.pt\"\n",
    "    \n",
    "    # 3. Copy and rename the file to your notebook root\n",
    "    shutil.copy(latest_weights, destination)\n",
    "    \n",
    "    print(f\"âœ… Success! Your LEGO model is saved as: {os.path.abspath(destination)}\")\n",
    "else:\n",
    "    print(\"âŒ Error: Could not find 'best.pt'. Did the training finish successfully?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv26 Quantization Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ___________ ____        ____  ____  ____\n",
      "   / ____/ ___// __ \\      / __ \\/ __ \\/ __ \\\n",
      "  / __/  \\__ \\/ /_/ /_____/ /_/ / /_/ / / / /\n",
      " / /___ ___/ / ____/_____/ ____/ ____/ /_/ /\n",
      "/_____//____/_/         /_/   /_/    \\___\\_\\\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# System Imports\n",
    "import os\n",
    "import sys\n",
    "# Add pipeline source to path for local imports\n",
    "sys.path.append('scripts')\n",
    "\n",
    "import types\n",
    "import torch\n",
    "import esp_ppq.lib as PFL\n",
    "from esp_ppq.executor import TorchExecutor\n",
    "from esp_ppq.core import QuantizationVisibility, TargetPlatform\n",
    "from esp_ppq.api import get_target_platform\n",
    "from esp_ppq.api.interface import load_onnx_graph\n",
    "from esp_ppq.quantization.optim import (\n",
    "    QuantizeSimplifyPass, QuantizeFusionPass, ParameterQuantizePass,\n",
    "    RuntimeCalibrationPass, PassiveParameterQuantizePass, QuantAlignmentPass\n",
    ")\n",
    "from ultralytics.data.utils import check_det_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Important Configuration ---\n",
    "IMG_SZ_I = 512   # any size\n",
    "PLATFORM = \"p4\"  # p4 or s3\n",
    "DATA_YAML_FILE_I = \"lego_data/data.yaml\" # coco.yaml Ultralytics default YAML file ,you can use your own\n",
    "PROJECT_NAME = \"lego\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "class QATConfig:\n",
    "    # Training Parameters\n",
    "    EPOCHS = 20           # 640 img_sz need about 10 epochs\n",
    "    BATCH_SIZE = 20       # on 8GB VRAM use 14 for 640 img_sz and 20 for 512 img_sz\n",
    "    IMG_SZ = IMG_SZ_I\n",
    "    DATA_FRACTION = 1.0   # Use 0.005 (0.5%) of dataset for fast debugging\n",
    "    SEED = 1234\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Optimizer\n",
    "    OPTIMIZER_LR = 1e-6\n",
    "    OPTIMIZER_MOMENTUM = 0.937\n",
    "    OPTIMIZER_WEIGHT_DECAY = 5e-4\n",
    "    \n",
    "    # Data Settings\n",
    "    DATA_YAML_FILE = DATA_YAML_FILE_I\n",
    "    DATA_FALLBACK_PATH = \"coco2017/images/train2017\"\n",
    "    CALIB_MAX_IMAGES = 8192\n",
    "    CALIB_VALID_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "    \n",
    "    # Quantization Settings\n",
    "    TARGET_PLATFORM = get_target_platform(\"esp32\"+PLATFORM, 8)\n",
    "    CALIB_STEPS = 32\n",
    "    QUANT_CALIB_METHOD = \"kl\"\n",
    "    QUANT_ALIGNMENT = \"Align to Output\"\n",
    "    EXPORT_OPSET = 13\n",
    "    EXPORT_DYNAMIC = False \n",
    "    \n",
    "    # Loss Defaults (Standard YOLOv8/v10/v26 defaults)\n",
    "    LOSS_DEFAULTS = {\n",
    "        'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0,\n",
    "        'label_smoothing': 0.0, 'nbs': 64, 'hsv_h': 0.015, 'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5,\n",
    "        'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5,\n",
    "        'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0,\n",
    "    }\n",
    "\n",
    "    # Model Paths\n",
    "    # Assuming current directory\n",
    "    BASE_DIR = os.getcwd()\n",
    "    MODEL_NAME = \"yolo26n\"+\"_\"+PROJECT_NAME \n",
    "    PT_FILE = f\"{MODEL_NAME}.pt\"\n",
    "    ONNX_FILE = f\"{MODEL_NAME}_train.onnx\"\n",
    "    \n",
    "    # Derived Paths - Output Structure updated for GitHub workflow\n",
    "    ESPDL_OUTPUT_DIR = os.path.join(BASE_DIR, \"output\", f\"{PROJECT_NAME}_{IMG_SZ}_s8_{PLATFORM}\")\n",
    "    ONNX_PATH = os.path.join(ESPDL_OUTPUT_DIR, ONNX_FILE)\n",
    "    \n",
    "    # Plotting\n",
    "    VAL_PLOT_MAX_BATCHES = 3\n",
    "\n",
    "    # Validation Batch Size\n",
    "    VAL_BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered 'Mod' handler for PPQ.\n",
      "Virtual Config injected and Modules initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- Virtual Module Injection ---\n",
    "# This tricks Python into thinking 'config.py' exists and contains our QATConfig class.\n",
    "# This allows 'trainer.py' and 'utils.py' to do 'from config import QATConfig'\n",
    "\n",
    "if 'config' in sys.modules:\n",
    "    # If it exists, update it\n",
    "    sys.modules['config'].QATConfig = QATConfig\n",
    "else:\n",
    "    # Create a dummy module\n",
    "    config_module = types.ModuleType('config')\n",
    "    config_module.QATConfig = QATConfig\n",
    "    sys.modules['config'] = config_module\n",
    "\n",
    "# Must ensure output directory exists for config files early usage if any\n",
    "if not os.path.exists(QATConfig.ESPDL_OUTPUT_DIR):\n",
    "    os.makedirs(QATConfig.ESPDL_OUTPUT_DIR)\n",
    "\n",
    "# Now we can safely import our local modules that depend on 'config'\n",
    "from utils import seed_everything, register_mod_op, patch_v8_detection_loss, get_exclusive_ancestors\n",
    "from dataset import get_calibration_loader, get_train_loader\n",
    "from trainer import QATTrainer\n",
    "from export import apply_export_patches, ESP_YOLO\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed_everything(QATConfig.SEED)\n",
    "register_mod_op()\n",
    "patch_v8_detection_loss()\n",
    "print(\"Virtual Config injected and Modules initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP-PPQ ONNX Compatibility Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ESP-PPQ Runtime Patches...\n",
      "  [x] Patched OnnxParser.refine_graph\n",
      "  [x] Patched Backend: Slice\n",
      "  [x] Patched Backend: Gather\n",
      "ESP-PPQ Runtime Patches Applied Successfully.\n"
     ]
    }
   ],
   "source": [
    "from esp_ppq_patch import apply_esp_ppq_patches\n",
    "apply_esp_ppq_patches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Preparation & Export\n",
    "We load the PyTorch checkpoint (`.pt`) and export it to ONNX. \n",
    "Critically, we apply `ESP_Attention` patches here to ensure the exported ONNX graph uses static reshaping, preventing runtime errors on the target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ESP-DL patches for export...\n",
      "Patched 2 Attention modules.\n",
      "Patched Detect module: <class 'ultralytics.nn.modules.head.Detect'>\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CPU (13th Gen Intel Core(TM) i7-13650HX)\n",
      ">> Fuse method blocked! Keeping all heads.\n",
      "YOLO26n summary (fused): 146 layers, 2,505,224 parameters, 0 gradients, 5.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo26n_lego.pt' with input shape (16, 3, 512, 512) BCHW and output shape(s) ((16, 32, 64, 64), (16, 32, 32, 32), (16, 32, 16, 16), (16, 32, 64, 64), (16, 32, 32, 32), (16, 32, 16, 16)) (5.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 13...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.3s, saved as 'c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4\\yolo26n_lego_train.onnx' (9.7 MB)\n",
      "\n",
      "Export complete (2.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\u001b[0m\n",
      "Predict:         yolo predict task=detect model=c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data\\data_512_s8_p4\\yolo26n_lego_train.onnx imgsz=512 \n",
      "Validate:        yolo val task=detect model=c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data\\data_512_s8_p4\\yolo26n_lego_train.onnx imgsz=512 data=lego_data/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Export complete.\n",
      "Loading yolo26n_lego.pt to extract metadata...\n",
      "Extracted Metadata: NC=28, RegMax=1, Stride=[8.0, 16.0, 32.0]\n"
     ]
    }
   ],
   "source": [
    "def extract_model_meta():\n",
    "    \"\"\"Dynamically extracts model metadata (NC, RegMax, etc.) from the PT checkpoint.\"\"\"\n",
    "    print(f\"Loading {QATConfig.PT_FILE} to extract metadata...\")\n",
    "    # We use ESP_YOLO here just to inspect, but standard YOLO would work too for this part\n",
    "    tmp_model = ESP_YOLO(QATConfig.PT_FILE)\n",
    "    \n",
    "    # Access the Detect Head (last layer)\n",
    "    detect_head = tmp_model.model.model[-1]\n",
    "    \n",
    "    # Derive input channels (ch) from the first layer of cv2\n",
    "    ch = [m[0].conv.in_channels for m in detect_head.cv2]\n",
    "    \n",
    "    meta = {\n",
    "        'nc': detect_head.nc,\n",
    "        'reg_max': detect_head.reg_max,\n",
    "        'stride': detect_head.stride,\n",
    "        'ch': ch\n",
    "    }\n",
    "    \n",
    "    if isinstance(meta['stride'], torch.Tensor):\n",
    "        meta['stride'] = meta['stride'].tolist()\n",
    "        \n",
    "    print(f\"Extracted Metadata: NC={meta['nc']}, RegMax={meta['reg_max']}, Stride={meta['stride']}\")\n",
    "    return meta\n",
    "\n",
    "def prepare_onnx():\n",
    "    \"\"\"Ensures the correct ONNX model exists with all patches applied.\"\"\"\n",
    "    try:\n",
    "        # Load using ESP_YOLO to enforce custom export logic\n",
    "        model = ESP_YOLO(QATConfig.PT_FILE)\n",
    "        \n",
    "        # Apply patches (Attention & Detect)\n",
    "        apply_export_patches(model)\n",
    "        \n",
    "        # Export\n",
    "        model.export(format=\"onnx\", opset=QATConfig.EXPORT_OPSET, simplify=True, \n",
    "                        imgsz=QATConfig.IMG_SZ, dynamic=QATConfig.EXPORT_DYNAMIC)\n",
    "        print(\"Export complete.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting model: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Run Preparation\n",
    "prepare_onnx()\n",
    "model_meta = extract_model_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantizer Initialization\n",
    "We load the ONNX graph and initialize the PPQ Quantizer.\n",
    "We also perform a graph analysis to separate the **Auxiliary Branch** (used for training guidance) from the **Main Branch** (used for inference). We disable quantization on the Aux branch to ensure gradients flow correctly without noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying auxiliary branch operators to disable quantization...\n",
      "Found 45 operators exclusive to auxiliary branch.\n"
     ]
    }
   ],
   "source": [
    "# Load Graph\n",
    "graph = load_onnx_graph(onnx_import_file=QATConfig.ONNX_PATH)\n",
    "\n",
    "# Identify and Disable Aux Layer Quantization\n",
    "output_names = list(graph.outputs.keys())\n",
    "aux_ops = set()\n",
    "if len(output_names) >= 6:\n",
    "    # Assuming order: [one2many_p3, ... one2one_p3, ...]\n",
    "    # Note: Custom exporter uses names one2many_p3 etc. which is explicitly handled here\n",
    "    aux_outputs = output_names[0:3]\n",
    "    main_outputs = output_names[3:6]\n",
    "    print(\"Identifying auxiliary branch operators to disable quantization...\")\n",
    "    aux_ops = get_exclusive_ancestors(graph, aux_outputs, main_outputs)\n",
    "    print(f\"Found {len(aux_ops)} operators exclusive to auxiliary branch.\")\n",
    "else:\n",
    "    print(\"WARNING: Graph output count < 6. Cannot separate aux/main branches.\")\n",
    "\n",
    "# Initialize Quantizer\n",
    "quantizer = PFL.Quantizer(platform=QATConfig.TARGET_PLATFORM, graph=graph)\n",
    "dispatching_table = PFL.Dispatcher(graph=graph, method=\"conservative\").dispatch(\n",
    "    quantizer.quant_operation_types\n",
    ")\n",
    "\n",
    "# Enforce FP32 for Aux ops and defaults\n",
    "for opname, platform in dispatching_table.items():\n",
    "    if platform == TargetPlatform.UNSPECIFIED:\n",
    "        dispatching_table[opname] = TargetPlatform(quantizer.target_platform)\n",
    "        \n",
    "for op in aux_ops:\n",
    "    if op.name in dispatching_table:\n",
    "        dispatching_table[op.name] = TargetPlatform.FP32\n",
    "\n",
    "# Apply Quantization\n",
    "for op in graph.operations.values():\n",
    "    quantizer.quantize_operation(op_name=op.name, platform=dispatching_table[op.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calibration\n",
    "Before training, we must calibrate the quantized parameters (scale/offset) using a representative dataset. This initializes the network in a good state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset at: C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\lego_data\\train\\images\n",
      "Fast image access  (ping: 0.00.0 ms, read: 431.9217.9 MB/s, size: 27.6 KB)\n",
      "\u001b[KScanning C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\lego_data\\train\\labels.cache... 7408 images, 3694 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7408/7408  0.0s\n",
      "\u001b[38;5;3m[WARNING][PPQ][2026-02-07 05:15:32]:  \u001b[mUnexpected input value of operation /model.11/Resize, recieving \"None\" at its input 1\n",
      "\u001b[38;5;3m[WARNING][PPQ][2026-02-07 05:15:32]:  \u001b[mUnexpected input value of operation /model.14/Resize, recieving \"None\" at its input 1\n",
      "Running Calibration Pipeline...\n",
      "[05:15:32] PPQ Quantize Simplify Pass Running ...         Finished.\n",
      "[05:15:32] PPQ Quantization Fusion Pass Running ...       Finished.\n",
      "[05:15:32] PPQ Parameter Quantization Pass Running ...    Finished.\n",
      "[05:15:32] PPQ Runtime Calibration Pass Running ...       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  5.25it/s]\n",
      "Calibration Progress(Phase 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[05:15:47] PPQ Passive Parameter Quantization Running ... Finished.\n",
      "[05:15:47] PPQ Quantization Alignment Pass Running ...    Finished.\n"
     ]
    }
   ],
   "source": [
    "# Data Loaders\n",
    "data_cfg = check_det_dataset(QATConfig.DATA_YAML_FILE)\n",
    "cali_loader = get_calibration_loader(data_cfg)\n",
    "train_loader = get_train_loader(data_cfg)\n",
    "\n",
    "# Tracing\n",
    "executor = TorchExecutor(graph=graph)\n",
    "dummy_input = torch.zeros([1, 3, QATConfig.IMG_SZ, QATConfig.IMG_SZ]).to(QATConfig.DEVICE)\n",
    "executor.tracing_operation_meta(inputs=dummy_input)\n",
    "\n",
    "# Calibration Pipeline\n",
    "print(\"Running Calibration Pipeline...\")\n",
    "pipeline = PFL.Pipeline([\n",
    "    QuantizeSimplifyPass(),\n",
    "    QuantizeFusionPass(activation_type=quantizer.activation_fusion_types),\n",
    "    ParameterQuantizePass(),\n",
    "    RuntimeCalibrationPass(method=QATConfig.QUANT_CALIB_METHOD),\n",
    "    PassiveParameterQuantizePass(clip_visiblity=QuantizationVisibility.EXPORT_WHEN_ACTIVE),\n",
    "    QuantAlignmentPass(elementwise_alignment=QATConfig.QUANT_ALIGNMENT),\n",
    "])\n",
    "\n",
    "pipeline.optimize(\n",
    "    calib_steps=QATConfig.CALIB_STEPS,\n",
    "    collate_fn=(lambda x: x.type(torch.float).to(QATConfig.DEVICE)),\n",
    "    graph=graph,\n",
    "    dataloader=cali_loader,\n",
    "    executor=executor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Validation (Check PTQ Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Trainer for Baseline Check...\n",
      "Loading YOLOv26n model in Trainer to access correct Loss function...\n",
      "Initializing Persistent Validator (reusing dataloader)...\n",
      "Running Baseline Validation on Quantized Graph...\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 403.7246.3 MB/s, size: 24.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\lego_data\\valid\\labels.cache... 628 images, 302 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 628/628  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.8it/s 14.7s0.5s\n",
      "                   all        628       1292      0.801      0.696      0.798      0.624\n",
      "\n",
      "--- Baseline Results ---\n",
      "PTQ mAP50-95: 0.624\n",
      "Target: This serves as the baseline. QAT will now attempt to improve this score.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer just for evaluation\n",
    "print(\"Initializing Trainer for Baseline Check...\")\n",
    "trainer = QATTrainer(graph=graph, model_meta=model_meta, device=QATConfig.DEVICE)\n",
    "\n",
    "# Run validation on the graph in its current state (after Calibration/PTQ, before Training)\n",
    "print(\"Running Baseline Validation on Quantized Graph...\")\n",
    "ptq_mAP = trainer.eval()\n",
    "\n",
    "print(f\"\\n--- Baseline Results ---\")\n",
    "print(f\"PTQ mAP50-95: {ptq_mAP:.3f}\")\n",
    "print(f\"Target: This serves as the baseline. QAT will now attempt to improve this score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. QAT Training Loop\n",
    "We now fine-tune the quantized model. The `QATTrainer` handles the forward pass through the quantized graph (simulated by PPQ) and the backward pass to update weights.\n",
    "\n",
    "Note: The validation step uses our `QuantizedModelValidator` which manually decodes the raw graph outputs using the metadata extracted earlier (`NC`, `RegMax`, `Estride`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting QAT Training...\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:14<00:00,  1.01s/it, loss=5.8876] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 22.4570\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 3.5it/s 7.7s0.3s\n",
      "                   all        628       1292      0.871      0.756      0.831      0.676\n",
      "Epoch: 1, mAP50-95: 0.676\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 2/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:13<00:00,  1.01s/it, loss=6.1593] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 21.3418\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.0it/s 13.6s0.5s\n",
      "                   all        628       1292      0.854      0.756      0.839      0.689\n",
      "Epoch: 2, mAP50-95: 0.689\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 3/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [05:55<00:00,  1.04it/s, loss=4.3960] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 20.5645\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.9it/s 13.9s0.5s\n",
      "                   all        628       1292      0.866      0.755       0.84      0.691\n",
      "Epoch: 3, mAP50-95: 0.691\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 4/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [05:51<00:00,  1.05it/s, loss=4.9233] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 20.2086\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.0it/s 13.3s0.5s\n",
      "                   all        628       1292      0.878      0.752      0.841      0.693\n",
      "Epoch: 4, mAP50-95: 0.693\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 5/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:35<00:00,  1.06s/it, loss=5.9371] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 20.0348\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.0it/s 13.4s0.5s\n",
      "                   all        628       1292      0.874      0.766      0.843      0.693\n",
      "Epoch: 5, mAP50-95: 0.693\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 6/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:25<00:00,  1.04s/it, loss=8.2322] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 19.8749\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.0it/s 13.3s0.5s\n",
      "                   all        628       1292      0.869      0.766      0.845      0.693\n",
      "Epoch: 6, mAP50-95: 0.693\n",
      "\n",
      "--- Epoch 7/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:18<00:00,  1.02s/it, loss=8.5849] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 19.5683\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.1it/s 13.0s0.5s\n",
      "                   all        628       1292      0.905      0.733      0.837      0.695\n",
      "Epoch: 7, mAP50-95: 0.695\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 8/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:34<00:00,  1.06s/it, loss=11.2508]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 19.3319\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.9it/s 14.1s0.5s\n",
      "                   all        628       1292      0.853      0.772      0.845      0.696\n",
      "Epoch: 8, mAP50-95: 0.696\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 9/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:17<00:00,  1.02s/it, loss=9.2642] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 19.2257\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.0it/s 13.4s0.5s\n",
      "                   all        628       1292      0.857      0.775      0.845      0.701\n",
      "Epoch: 9, mAP50-95: 0.701\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 10/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [05:37<00:00,  1.10it/s, loss=4.4087] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 19.0985\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 3.4it/s 7.9s0.3s\n",
      "                   all        628       1292      0.887      0.759      0.844      0.699\n",
      "Epoch: 10, mAP50-95: 0.699\n",
      "\n",
      "--- Epoch 11/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:27<00:00,  1.05s/it, loss=5.1320] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 18.8922\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.1it/s 12.8s0.5s\n",
      "                   all        628       1292      0.879      0.757      0.844      0.703\n",
      "Epoch: 11, mAP50-95: 0.703\n",
      "New best mAP! Saving to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4...\n",
      "\n",
      "--- Epoch 12/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:15<00:00,  1.01s/it, loss=4.2747] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 18.8634\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.0it/s 13.6s0.5s\n",
      "                   all        628       1292      0.913      0.744      0.847      0.702\n",
      "Epoch: 12, mAP50-95: 0.702\n",
      "\n",
      "--- Epoch 13/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [06:31<00:00,  1.05s/it, loss=6.0918] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: 18.7304\n",
      "Ultralytics 8.4.7  Python-3.9.21 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 2.1it/s 13.1s0.5s\n",
      "                   all        628       1292      0.873      0.769      0.848        0.7\n",
      "Epoch: 13, mAP50-95: 0.700\n",
      "\n",
      "--- Epoch 14/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 151/371 [02:27<03:34,  1.03it/s, loss=22.2825]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQATConfig\u001b[38;5;241m.\u001b[39mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Train Epoch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[0;32m     14\u001b[0m current_mAP \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\scripts\\trainer.py:134\u001b[0m, in \u001b[0;36mQATTrainer.epoch\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m    131\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    132\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader))\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bidx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[0;32m    135\u001b[0m     _, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(batch, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\orani\\anaconda3\\envs\\env_dl\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\ultralytics-8.4.7\\ultralytics\\data\\base.py:376\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_and_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\ultralytics-8.4.7\\ultralytics\\data\\base.py:389\u001b[0m, in \u001b[0;36mBaseDataset.get_image_and_label\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    387\u001b[0m label \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index])  \u001b[38;5;66;03m# requires deepcopy() https://github.com/ultralytics/ultralytics/pull/1948\u001b[39;00m\n\u001b[0;32m    388\u001b[0m label\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# shape is for rect, remove it\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m], label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m], label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratio_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    391\u001b[0m     label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    392\u001b[0m     label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    393\u001b[0m )  \u001b[38;5;66;03m# for evaluation\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrect:\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\ultralytics-8.4.7\\ultralytics\\data\\base.py:235\u001b[0m, in \u001b[0;36mBaseDataset.load_image\u001b[1;34m(self, i, rect_mode)\u001b[0m\n\u001b[0;32m    233\u001b[0m         im \u001b[38;5;241m=\u001b[39m imread(f, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2_flag)  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# read image\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2_flag\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Not Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\bilel\\git_projects\\yolo26\\version1_yolo26\\ultralytics-8.4.7\\ultralytics\\utils\\patches.py:42\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Fallback for formats OpenCV imdecode may not support (AVIF, HEIC)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.avif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.heic\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting QAT Training...\")\n",
    "\n",
    "if not os.path.exists(QATConfig.ESPDL_OUTPUT_DIR):\n",
    "    os.makedirs(QATConfig.ESPDL_OUTPUT_DIR)\n",
    "\n",
    "best_mAP = 0\n",
    "for epoch in range(QATConfig.EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{QATConfig.EPOCHS} ---\")\n",
    "    \n",
    "    # Train Epoch\n",
    "    trainer.epoch(train_loader)\n",
    "    \n",
    "    # Validate\n",
    "    current_mAP = trainer.eval()\n",
    "    print(f\"Epoch: {epoch+1}, mAP50-95: {current_mAP:.3f}\")\n",
    "    \n",
    "    if current_mAP > best_mAP:\n",
    "        best_mAP = current_mAP\n",
    "        print(f\"New best mAP! Saving to {QATConfig.ESPDL_OUTPUT_DIR}...\")\n",
    "        \n",
    "        # Save Native Graph using the new helper method\n",
    "        trainer.save_graph(os.path.join(QATConfig.ESPDL_OUTPUT_DIR, \"Best_yolo26n.native\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Best Graph...\n",
      "Best Graph Reloaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Best Graph back into memory at the end\n",
    "print(\"Reloading Best Graph...\")\n",
    "trainer.load_graph(os.path.join(QATConfig.ESPDL_OUTPUT_DIR, \"Best_yolo26n.native\"))\n",
    "# Update global graph \n",
    "graph = trainer.graph \n",
    "print(\"Best Graph Reloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Best Graph...\n",
      "Preparing Graph for Inference...\n",
      "Removing Aux Heads: ['one2many_p3', 'one2many_p4', 'one2many_p5']\n",
      "Starting Safe Pruning Procedure...\n",
      "Pruning Finished. Total Rounds: 11\n",
      "Splitting one2one_p3 at Source Concat (/model.23/Concat_3)...\n",
      "  -> Created one2one_p3_box and one2one_p3_cls\n",
      "Splitting one2one_p4 at Source Concat (/model.23/Concat_4)...\n",
      "  -> Created one2one_p4_box and one2one_p4_cls\n",
      "Splitting one2one_p5 at Source Concat (/model.23/Concat_5)...\n",
      "  -> Created one2one_p5_box and one2one_p5_cls\n",
      "Updating Graph Output Order...\n",
      "Registered 6 split outputs.\n",
      "Starting Safe Pruning Procedure...\n",
      "Pruning Finished. Total Rounds: 2\n",
      "Final Graph Outputs: ['one2one_p3_box', 'one2one_p4_box', 'one2one_p5_box', 'one2one_p3_cls', 'one2one_p4_cls', 'one2one_p5_cls']\n",
      "Exporting Split Inference Model to c:\\Users\\orani\\bilel\\git_projects\\yolo26\\yolo26n_esp32_repo\\esp-dl\\examples\\tutorial\\how_to_quantize_model\\quantize_yolo26\\output\\lego_data/data_512_s8_p4\\yolo26n_lego_512_s8_p4.espdl...\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_17 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_16 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_17 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_16 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_17 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_16 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip onnx::Split_262 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_14 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_4 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_7 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_8 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_10 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_12 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_87 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_17 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_90 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.10/m/m.0/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_92 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_95 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_16 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_2 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_5 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip  because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_3 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_15 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_6 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_9 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_11 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_13 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_97 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_19 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_100 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip /model.22/m.0/m.0.1/attn/Softmax_output_0 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_102 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_105 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mSkip PPQ_Variable_18 because it's not exportable\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2026-02-07 07:21:28]:  \u001b[mskip not QuantableOperation\n",
      "Export Done!\n"
     ]
    }
   ],
   "source": [
    "import esp_ppq.lib as PFL\n",
    "from config import QATConfig\n",
    "import os\n",
    "from esp_ppq.api import load_native_graph\n",
    "from esp_ppq.IR import BaseGraph  \n",
    "\n",
    "# --- Helper Function: Robust Graph Pruning ---\n",
    "def prune_graph_safely(graph: BaseGraph) -> BaseGraph:\n",
    "    \"\"\"\n",
    "    Robust pruning function for ESP-PPQ graphs.\n",
    "    Safely removes disconnected operations and unused variables.\n",
    "    \"\"\"\n",
    "    print(\"Starting Safe Pruning Procedure...\")\n",
    "    round_count = 0\n",
    "    while True:\n",
    "        this_round_op_removed = 0\n",
    "        this_round_var_removed = 0\n",
    "        \n",
    "        # A. Find Dead Ops\n",
    "        dead_ops = []\n",
    "        for op in list(graph.operations.values()):\n",
    "            is_output = any(var.name in graph.outputs for var in op.outputs)\n",
    "            has_consumers = any(len(var.dest_ops) > 0 for var in op.outputs)\n",
    "            \n",
    "            if not is_output and not has_consumers:\n",
    "                dead_ops.append(op)\n",
    "        \n",
    "        # Remove Dead Ops Safely\n",
    "        for op in dead_ops:\n",
    "            for var in list(op.inputs):\n",
    "                 op.inputs.remove(var)\n",
    "                 if op in var.dest_ops:\n",
    "                     var.dest_ops.remove(op)\n",
    "            graph.remove_operation(op, keep_coherence=False)\n",
    "            this_round_op_removed += 1\n",
    "            \n",
    "        # B. Find Dead Variables\n",
    "        dead_vars = []\n",
    "        for var in list(graph.variables.values()):\n",
    "            is_input = var.name in graph.inputs\n",
    "            is_output = var.name in graph.outputs\n",
    "            if is_input or is_output: continue\n",
    "            \n",
    "            if len(var.dest_ops) == 0:\n",
    "                dead_vars.append(var)\n",
    "                 \n",
    "        # Remove Dead Variables\n",
    "        for var in dead_vars:\n",
    "            if var.name in graph.variables:\n",
    "                graph.variables.pop(var.name)\n",
    "                this_round_var_removed += 1\n",
    "        \n",
    "        round_count += 1\n",
    "        if this_round_op_removed == 0 and this_round_var_removed == 0:\n",
    "            break\n",
    "            \n",
    "    print(f\"Pruning Finished. Total Rounds: {round_count}\")\n",
    "    return graph\n",
    "\n",
    "# --- MAIN LOGIC: Split Outputs at Concat Source ---\n",
    "\n",
    "print(\"Reloading Best Graph...\")\n",
    "native_graph_path = os.path.join(QATConfig.ESPDL_OUTPUT_DIR, \"Best_yolo26n.native\")\n",
    "graph = load_native_graph(import_file=native_graph_path)\n",
    "\n",
    "print(\"Preparing Graph for Inference...\")\n",
    "\n",
    "# 1. Remove Aux Heads First (Cleanup)\n",
    "output_names = list(graph.outputs.keys())\n",
    "if len(output_names) >= 6:\n",
    "    aux_heads = output_names[0:3] \n",
    "    print(f\"Removing Aux Heads: {aux_heads}\")\n",
    "    for name in aux_heads:\n",
    "        if name in graph.outputs:\n",
    "            graph.outputs.pop(name)\n",
    "    prune_graph_safely(graph)\n",
    "\n",
    "# 2. Apply Splitting Strategy\n",
    "targets = [\"one2one_p3\", \"one2one_p4\", \"one2one_p5\"]\n",
    "collected_outputs = {}\n",
    "\n",
    "for target_name in targets:\n",
    "    if target_name in graph.outputs:\n",
    "        original_output_var = graph.variables[target_name]\n",
    "        producer = original_output_var.source_op \n",
    "        \n",
    "        if producer and producer.type == \"Concat\":\n",
    "            print(f\"Splitting {target_name} at Source Concat ({producer.name})...\")\n",
    "            \n",
    "            box_var = None\n",
    "            cls_var = None\n",
    "            \n",
    "            # Inspect Concat inputs to find Box(4) and Cls(80)\n",
    "            for input_var in producer.inputs:\n",
    "                dims = input_var.shape\n",
    "                if dims is not None:\n",
    "                    if 4 in dims: box_var = input_var\n",
    "                    elif model_meta['nc'] in dims: cls_var = input_var\n",
    "            \n",
    "            if box_var and cls_var:\n",
    "                # Rename Scheme: Suffix per Request\n",
    "                pair_config = [\n",
    "                    (box_var, f\"{target_name}_box\"),  # e.g. one2one_p3_box\n",
    "                    (cls_var, f\"{target_name}_cls\")   # e.g. one2one_p3_cls\n",
    "                ]\n",
    "                \n",
    "                for var, new_name in pair_config:\n",
    "                    old_name = var.name\n",
    "                    \n",
    "                    # Robust Renaming (Modify Private + Registry)\n",
    "                    if old_name in graph.variables:\n",
    "                        graph.variables.pop(old_name)\n",
    "                    \n",
    "                    var._name = new_name\n",
    "                    graph.variables[new_name] = var\n",
    "                    \n",
    "                    collected_outputs[new_name] = var\n",
    "                \n",
    "                # Update Graph Outputs: Remove old name\n",
    "                graph.outputs.pop(target_name)\n",
    "                \n",
    "                # Properly Remove Concat Op\n",
    "                graph.remove_operation(producer, keep_coherence=False)\n",
    "                # Unlink inputs\n",
    "                for var in producer.inputs:\n",
    "                    if producer in var.dest_ops:\n",
    "                        var.dest_ops.remove(producer)\n",
    "\n",
    "                print(f\"  -> Created {pair_config[0][1]} and {pair_config[1][1]}\")\n",
    "            else:\n",
    "                print(f\"ERROR: Shape mismatch for {target_name}\")\n",
    "        else:\n",
    "             print(f\"WARNING: Source for {target_name} is not Concat.\")\n",
    "\n",
    "# 3. Register New Outputs in Strict Order (Box Group then Cls Group)\n",
    "final_output_list = [\n",
    "    \"one2one_p3_box\", \"one2one_p4_box\", \"one2one_p5_box\",\n",
    "    \"one2one_p3_cls\", \"one2one_p4_cls\", \"one2one_p5_cls\"\n",
    "]\n",
    "\n",
    "print(\"Updating Graph Output Order...\")\n",
    "graph.outputs.clear() # Enforce strict order\n",
    "count_added = 0\n",
    "for name in final_output_list:\n",
    "    if name in collected_outputs:\n",
    "        graph.outputs[name] = collected_outputs[name]\n",
    "        count_added += 1\n",
    "\n",
    "print(f\"Registered {count_added} split outputs.\")\n",
    "\n",
    "# 4. Final Prune\n",
    "prune_graph_safely(graph)\n",
    "\n",
    "print(f\"Final Graph Outputs: {list(graph.outputs.keys())}\") \n",
    "\n",
    "# 5. Export\n",
    "inference_export_path = os.path.join(QATConfig.ESPDL_OUTPUT_DIR, f\"{QATConfig.MODEL_NAME}_{QATConfig.IMG_SZ}_s8_{PLATFORM}.espdl\")\n",
    "print(f\"Exporting Split Inference Model to {inference_export_path}...\")\n",
    "\n",
    "exporter = PFL.Exporter(platform=QATConfig.TARGET_PLATFORM)\n",
    "exporter.export(inference_export_path, graph=graph)\n",
    "print(\"Export Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
